\documentclass[a4paper, 12pt]{article}

%%%%%%%%%%%%
% Packages %
%%%%%%%%%%%%

\usepackage[english]{babel}
\usepackage{packages/sleek}

\addbibresource{./resources/bib/references.bib}


\newcommand{\projectTitle}{KUKA YouBot Revival and System Development Project}
\newcommand{\projectSubtitle}{Documentation of progress through project, in requirements of Final Project in DSD}
\newcommand{\authorName}{Aditya Agrawal}
\newcommand{\advisorName}{assistant professor Tomasz Kucner}
\newcommand{\supervisorName}{senior university lecturer Salu Ylirisku}
\newcommand{\courseName}{ELEC-C0302 Final Project in Digital Systems and Design}
\newcommand{\universityName}{Aalto University}


\newcommand{\commentout}[1]{}
\newif\ifshowadi
\showaditrue% Set to \showaditrue to display comments on extending thesis

\newcommand{\adi}[1]{\ifshowadi\textcolor{red}{#1}\fi}

\newif\ifshownotes
\shownotestrue% Set to \shownotestrue to display notes

\newcommand{\notes}[1]{\ifshownotes\textcolor{blue}{#1}\fi}




%%%%%%%%%%%%
% Document %
%%%%%%%%%%%%

\begin{document}

%%%%%%%%%%%%%%
% Title-page %
%%%%%%%%%%%%%%
    \begin{titlepage}
        \raggedright
        % Define variables for title page
        

        \vspace*{2cm}

        {\Huge \textbf{\projectTitle}}\\[0.5cm]
        {\Large \projectSubtitle}\\[2cm]

        \textbf{Author:} \authorName\\[0.3cm]
        \textbf{Advisor:} \advisorName\\[0.3cm]
        \textbf{Supervisor:} \supervisorName\\[2cm]

        \courseName \\
        \universityName\\[0.5cm]
        \today

        \vfill
    \end{titlepage}
    \romantableofcontents

    \commentout{\section{Ideas \& Drafts (NOT ON FINAL REPORT)}
    structure: 
    My work
    reflection
    appendix: user manual

    things I did i want to add:
    - add in the initial project plan
    - add in the initial state of everything
    - known documentation

    - libfreenect and kinect camera
    - communication with onboard computer
    - enabling it to initially move through provided demos
    - utilising ROS1-ROS2 bridge (fail)
    - fixing the battery up 
    - writing my own programs to move the bot 
    
    - how did my goals change with time?
    - project management brief overview
    Teach and repeat background:
    https://furgalep.github.io/bib/mcmanus_icra12.pdf
    https://www.sciencedirect.com/science/article/pii/S0921889020304176
    https://arxiv.org/pdf/2309.15405
    https://clearpathrobotics.com/blog/2018/07/visual-teach-and-repeat-closer-look-part-1/}

    
    
    \section{Introduction}

    \subsection{Motivation}
    %\adi{Motivation: Why is this project worthwhile? What did I stand to gain from this? This part is forward-looking and conceptual; it establishes the intent and value proposition for the project.}
    %\notes{1.1 Motivation Why this project? Explore the potential of repurposing legacy robotic platforms like the KUKA YouBot. Address the need for longer lifespans in academic robotics hardware. Personal/academic gain: Engage with low-level robotics systems. Learn system integration, perception, and hardware/software interfacing.}

    In the rapidly evolving field of robotics, expensive hardware platforms often become obsolete quickly. This is not because of physical wear and tear or a lack of functionality, but rather due to quick advancements in software and infrastructure. For example, artificial intelligence and machine learning have made significant strides in recent years, leading to the development of humanoid robots with advanced capabilities. As a result, older platforms become less relevant and lack the necessary support for extending their potential lifespan, despite inherent capabilities. 

    The KUKA YouBot is a prime example of this phenomenon. It was once a popular platform for research and education in robotics in the mid-2010s, but has been since discontinued and is no longer supported by the manufacturer. This mobile robot base is quite robust, compact and utilizes open-source drivers. It can potentially serve a variety of purposes, including autonomous navigation, perception and human-robot interaction with modern tools and sensors. Instead of discarding such platforms, we should explore these avenues to extend their lifespan and utility. 
    
    Thus, this project aims to explore the potential of deploying and repurposting legacy robotic hardware like the KUKA YouBot within the current landscape of robotics. By doing so, we can demonstrate the potential of long-term viability of older platforms whilst allowing for smooth integration with other systems. 

    \subsection{Project Overview}

    This project aims to document the reployment and quantitative measurement of the KUKA YouBot's capabilities, particularly in terms of navigation and odometry. 



    %\adi{Potential: Highlights unique physical and design attributes of the robot that make it worth saving. Why is it distinct? Robot's inherent capabilities and versatility. Mini technical pitch.}
    %\notes{1.3 Use Case Potential: Unique attributes of the YouBot: Compact, low-profile, omnidirectional drive. Reliable base hardware and extensibility. Application areas: Autonomous indoor navigation. HRI (Human-Robot Interaction) research. Visual/LIDAR-based perception projects. Education and prototyping platforms.}


    %


    %\subsection{Project Objectives and Scope}
    %\adi{Project objectives: What are the goals of the project? What do I want to achieve? This is a high-level overview of the project and its roadmap.}
    %\notes{1.4 Project Objectives and Scope: Initial objective: Full robot revival with autonomous navigation using a Kinect sensor. Revised direction: Due to constraints, focused on: Re-enabling hardware operation. Evaluating performance. Documenting the restoration process. What this document provides: Overview of the project flow. Assessment of hardware/software components. Challenges faced and how they were handled. Ideas for future directions.}
    
    %As such, the initial goal was to conduct a comprehensive revival of the robot and enable it to autonomously navigate a static environment using a low-cost camera. However, the goals shifted towards enabling the deployment of the robot, and documenting the quality of its various components. This document aims to provide a comprehensive overview of the project, including the initial state of the YouBot, the software and hardware components, the challenges faced during the revival process, and the potential future applications of the robot.

    %The motivation for this project stems from the need to explore the potential of repurposing legacy robotic hardware yadda yadda yadda


        

    \pagebreak

    \section{Initial state of YouBot}

    \adi{Needed: pictures of everything, flow chart diagram of the system, etc.}

    The KUKA YouBot was procured by the university in 2014, and has not been in use since 2019. At that time, the robot was considered to be quite antiquated, and the software and hardware were already outdated. Furthermore, the relevant websites hosting documentation and information are no longer available. This situation has only worsened over the years, and the starting point for this project through was an user manual uploaded on a third-party website marked as a draft version from 2013. 

    \subsection{About the Hardware}

    The YouBot is a mobile robotic platform developed by German automation company KUKA. First introduced in the early 2010s \notes{[cite]}, it was primarily designed for research and educational purposes in the field of robotics. To further this purpose, a significant portion of software used on the YouBot is open-source and available on GitHub \notes{[cite]}. 

    The YouBot typically consists of two main parts: a mobile base and a robotic arm. The mobile base is equipped with four omnidirectional mecanum wheels and motors for movement, alongside an onboard computer for processing and control. This onboard computer runs Ubuntu and ROS1, with conveniently provided drivers and wrappers, allowing for smooth software integration. The robotic arm has 5 degrees of freedom (DOF) and a two-finger gripper \notes{[cite]}, enabling it to perform a variety of tasks through the onboard computer. Since this project involves only the mobile base, we will not be discussing the arm in detail.

    The YouBot's open-source software stack and ROS compatibility provide a flexible foundation for both low-level hardware interfacing and high-level algorithm development. This robot and the attached sensor modules are thus particularly well-suited for research within mobile robotics, particularly those pertaining to navigation and perception, as well as human-robot interaction. 

    \subsection{Robot Base Overview}

    \notes{initial inspection\\}


    The robot base features a 24V power input via a 3-pin XLR connector, accessed through the top of the robot. In addition to this, there are two 24V 3-pin XLR output ports, indeded to power external sensors or other components such as robotic arms. On this top panel, one can also find two EtherCAT ports for consistent real-time communication with motion-oriented robotics (i.e. the robotic arm), as well as a standard Ethernet port for wired interfacing with an external computer or network. 

    Mobility is provided by four omnidirectional mecanum wheels and relevant motors. This allows for relatively smooth and precise movement through a combination of linear and rotational motion. The motors are controlled via the onboard computer, which can send and recieve data from the motors and provide relevant feedback.

    The onboard computer includes 6 USB2.0 ports, which can be used to connect various peripherals, such as a keyboard, mouse, USB, wireless adapter, etc. Additionally, there is a VGA port for connecting a monitor. \cite{githubYoubotOverview}  

    The attached top panel is a sensor and mounting plate, designed to allow for the convenient attachment of various sensors and accessories. [cite https://web.archive.org/web/20160613151621/http://www.youbot-store.com/accessories/mounting-and-sensor-plate]

    The robot base is also equipped with a slot for a sealed lead-acid battery (SLA), which can be used to power the robot when not connected to a wall outlet. The battery can connect to the robot via a 4-pin XLR connector. 

    \subsection{Additional Hardware Components}

    
    \notes{DESCRIBE THE INITIAL INSPECTION IN FULL HERE! TALK ABOUT THE PILLAR STUFF AND NUTS AND WHATNOT AS WELL!!!!}

    The YouBot also came with a variety of additional components and accessories to assist with sensor mounting and operation. These included a variety of nuts, bolts, and screws, as well as a hex key and several horizonal and vertical pillars. These pillars can be combined in a variety of ways to create a stable and secure mounting platform for the sensors. 

    \subsection{Onboard Computer Overview}
    The computer runs [this software] and ROS version []. I wasn't able to immediately boot up any tests to ensure if the robot itself was working at any stage in time. 

    \notes{what ports are there? what software is on there? ubuntu? initial setup? ROS version? software?}
    The onboard computer is an [] with an []. 

    It was running Ubuntu 12.04 LTS with ROS Hydro, which is a decade-old version of the operating system and the robot operating system. This version of Ubuntu is no longer supported, and the software is outdated and not compatible with most modern software and libraries. This will be detailed in a future section.

    Alongside the OS and ROS, the computer also had various drivers and wrappers installed to enable communication with the robot's motors and sensors. This could be done directly through C++ programs, or through the use of pre-made ROS packages. We have elected to use the latter for the purposes of developing a system on the YouBot, to allow for a seamless integration with the ROS ecosystem in the future, alongside a level of standardization and ease of use. 


    \subsection{Battery}
    
    The mobile robot base allows for a 24V power supply through a 4-pin XLR connector. It could also be operated without using a wired cable to the wall, by using a lead-acid battery originally which had a capacity of 5Ah and gave the YouBot an approximate runtime of 90 minutes. This lead-acid battery is \notes{[dimensions here]}. This battery is also connected through a 4-pin XLR connector. While not a standard connector for power supply (4-pin XLR connectors are typically used for audio equipment), it is very robust and secure for the purposes of a mobile robot. 

    However, the SLA batteries that were initially included with the YouBot were completely unusable. The lab engineer (Vesa Korhonen) had also put together a makeshift SLA battery in 2019, which had also degraded severely. 

    As such, either the original batteries had to be replaced, or the robot had to be continuously used with a wired connection to the wall. This would have been a significant limitation to the project had we not been able to create a makeshift replacement battery which will be discussed in section 4.4.
    

    \subsection{Sensors}
    
    Alongside the robot base and various hardware components, the YouBot was also equipped with a variety of sensors. These included a Kinect v1 camera and two Hokuyo URG-04LX laser rangefinders (, one of which had a broken mini-USB port, rendering it unusable). These sensors are commonly used in robotics research and are well-suited for navigation and perception tasks.

    \subsubsection{Kinect}  

    The Kinect v1 camera is a depth and RGB camera that was originally designed and sold in tandem with the XBOX 360 to enable motion tracking and gaming. Due to its low cost, high availability and ease of use, it had indirectly become a popular choice for robotics research as well.

    This Kinect camera module can be used through the use of open-source software such as libfreenect \notes{[cite]} to access the data from the various sensors on the module. Furthermore, this information could be processed using the OpenCV library and then used to enable the autonomous navigation as previously described. 

    \subsubsection{Hokuyo URG-04LX Laser Rangefinder}

    The Hokuyo URG-04LX is a 2D laser rangefinder that is commonly used in robotics research. It is a compact and lightweight sensor that provides high-resolution distance measurements in a 240-degree field of view. The URG-04LX is capable of measuring distances up to 4 meters with an accuracy of +/- 10 mm. It communicates with the onboard computer using a serial interface, making it easy to integrate into existing systems. 

    \subsection{Documentation}

    The documentation for the KUKA YouBot is sparse and unavailable for the most part. KUKA has removed most references to the product from their website, and the original youbot-store.com website is no longer available. Furthermore, the only available user manual for the YouBot online is a decade-old PDF file that was uploaded by a third-party user, and is marked as a draft version from 2013. 

    Thankfully, the YouBot was marketed as an open-source platform, and the drivers as well as various parts of software are available on GitHub. Furthermore, we were able to find some more information about the YouBot through the Wayback Machine, which had archived parts of the original website. While this archive is not complete by any means and is very tedious to comb through, it provides us with a powerful tool to piece together data about the YouBot and its use cases during its hayday.

    We've also taken the liberty of citing some YouBot related projects here.

    \subsection{Initial Project Goals}

    Considering the hardware and software components of the YouBot, the initial goals of this project involved a comprehensive revival of the robot and the enabling of autonomous navigation using the Kinect camera. This would showcase the potential of the YouBot in cutting-edge research despite its age. 

    Teach \& Repeat (T\&R) was considered to be an ideal candidate to allow for the autonomous navigation. This\notes{[cite]} is a two-phase robotic navigation method where a robot is first "taught" a path via human guidance or pre-recoded data. The sensor data captured during this phase can then be used to allow the robot to autonomously "repeat" the path later on, even in different environments.

    T\&R only requires a single camera for a basic implementation. It is a relatively simple method to implement through the use of open-source software and libraries, such as OpenCV and ROS. Furthermore, it is robust to changes in the environment and can dynamically correct errors through the use of visual odometry. As such, it has been a very popular research topic within the field of robotics, particularly in the context of mobile robots \notes{[cite]}. Much of the work done on extending T\&R aims to improve this robustness and scalability for a variety of sensors and use-cases. 

    \notes{some sort of flow diagram showing how everything would be connected, the ros stack would look like.}

    Here, figure [] shows an example of how the architecture for this system would have been implemented. This would have involved a wired connection to an external computer running ROS2 Jazzy and directly connected to the Kinect camera mounted on top of the YouBot. The onboard computer would have been used to control the motors and communicate with the sensors, while the external computer would have handled the processing and navigation tasks. The onboard computer and external computer would commuicate through a ROS1-ROS2 bridge, allowing for seamless integration of the two systems. 

    However, considering the age of the YouBot, lack of personal knowledge regarding robotics, as well as incompatible software, it was realised that this was not feasible. We will be discussing our new goals in the next section. 

    \pagebreak
    
    \section{Project Overview}

    \subsection{Technical Goals}

    The technical goals for this project involve the deployment and quantification of the robot's capabilities, particularly in terms of navigation and odometry. This would involve the following goals: 
    \begin{itemize}
        \item Inspecting the initial physical state of the YouBot
        \item Enabling the robot start up
        \item Enabling the running of the original demos
        \item Enabling the running of the ROS interface
        \item Enabling the ROS1-ROS2 bridge
        \item Enabling wireless connections to external computers using SSH and Ethernet
        \item Writing custom programs to control the YouBot
        \item Testing the movement and odometry of the YouBot
        \item Measuring the quality of movement and odometry by measuring their error
        \item Replacing the current deprecated batteries with a usable battery
        \item Documenting the revival process and potential future applications of the YouBot
    \end{itemize}
    
    The set of goals that have been formulated have deviated from the original goals, which were formulated based on experimenting and identifying the limitations of the robot. 

    \subsection{Learning Objectives}

    The learning objectives for this project involve the following:
    \begin{itemize}
        \item Develop hands-on experience in restoring and operating a legacy robot platform (KUKA YouBot)
        \item Gain proficiency in Linux systems and environment setup for robotics development
        \item Learn to write and use Bash scripts to automate setup, build, and deployment workflows
        \item Understand the architecture of the Robot Operating System (ROS1 \& ROS2), and learn to configure and launch ROS-based systems
        \item Learn to establish and manage secure communication with robotic systems using SSH and Ethernet
        \item Write and deploy custom ROS nodes for basic motion control of the YouBot platform
        \item Understand the principles of robot navigation and odometry, including error measurement and correction techniques
        \item Learn methods for documenting system restoration, experimental results, and identifying directions for future development
    \end{itemize}

    \subsection{System Architecture}
    Our intended setup was to use the YouBot as a mobile base with the Kinect camera mounted on top of it. The onboard computer of the YouBot would only be used to control the motors and communicate with the sensors. The actual bulk of the processing would be done on a seperate computer that runs ROS2 and enables the necessary navigation and perception stacks.  

    \pagebreak

    \section{System Development}
    \subsection{Booting up the YouBot}

    \notes{describe the booting up process here, what ports to use, how to connect to the onboard computer, etc.}

    \notes{furthermore describe issues with software that needed to be fixed, such as the bashrc file, the networking, etc.}

    The initial inspection was carried out as described in section 2. Since the onboard battery was completely dead, I connected the YouBot to a 24V power supply and booted it up. On long pressing the power button, the screen flashed on and I could see the voltage input for the robot, alongside options to turn the PC and motors on/off seperately. 

    After connecting a VGA monitor and keyboard and mouse, I was able to boot up the onboard PC and use it as any other computer. The wireless adapter connected to this onboard computer was also functional, and I was able to connect to the internet. This meant I could theoretically SSH into the computer from my personal laptop, but I was unable to do so at that time due to a lack of a static IP address.


    
    I was able to see the following software installed on the onboard computer: insert ROS version here and discuss the github repos that were already installed here. 

    There’s a lot of files from at least 6 years ago on this, and I believe a significant portion are from like 2013 or 14. Two folders that look especially important are ros\_stacks and youbot\_driver. One file of high importance is in the desktop: the Kuka YouBot User Manual. I took a copy of that to my personal computer using a thumbdrive.  
    
    \notes{discuss powering up, initial software inspection, static IP issue}
    
    
    \pagebreak

    \subsection{Running original demos}
    \notes{describe fixing network issue, and hten running the original demos.}

    An attempt was made to run the original demos upon turning on the computer. These original demos were stored here: [insert path here].
    However, the program was unable to run due to not detecting any devices on the eth1 port. This was assumedly due to the motor drivers not being initialised, or the wrong port being used. The user manual states eth0, but the onboard computer was using eth1. This was thus a simple fix of changing the port in the config file for the youbot\_driver. 

    
    After this issue was fixed, you can turn the motors on using that button on the screen. running the demo using the following command then allows you to access this thing through the terminal. it works to do shit.


    \subsection{Enabling wireless connections}

    The wireless issues was caused by a combination of no IPv4 address assigned to the onboard computer, and the onboard computer not being able to connect to the internet. This was fixed by changing the network settings in the Network Manager, and setting a static IP address for the onboard computer. This was done by editing the /etc/network/interfaces file and adding the following lines:

    \begin{verbatim}
    auto eth1
    iface eth1 inet static
        address
        netmask
        gateway
    \end{verbatim}

    Initially, the following commands were used to set the static IP address: 
    \begin{verbatim}
    sudo ifconfig eth1
    \end{verbatim}
    however, this would automatically delete itself inconsistently due to the Network Manager. This was thus changed to the above method, which would set the static IP address permanently. This is much more convenient long term. 

    One can then connect to 


    \pagebreak


    \subsection{Running ROS interface}

    \notes{
        so what packages were there?
    }

    \notes{describe the process of inspecting the installed software, the drivers and wrappers, and running the original demos.}
     \notes{rqt, rviz, the various topics and nodes, etc. }
    Finding the packages
    running these packages

    I had to find these packages by running history and then going through the bash history. I was able to find some relevant packages and then use them to run my shit. I also found some youbot\_driver to do this but i found it more convenient to do sudo bash this another youbot\_Driver because it was visible much more easily on the home system. 

    The demos through ROS allowed me to inspect many things within ROS as well, like the nodes,

    list nodes here and their purposes.

    the topics,

    list that here,

    discuss rqt and rviz here

    \pagebreak

    \pagebreak
    \subsection{ROS1-ROS2 Bridge}

    One of the first tasks I decided to embark on after getting the robot up and running was to set up the ROS1-ROS2 bridge. This was the most important link within the system, as it would allow the robot to seamless access the ROS2 navigation stack and enable it to access the computational resources of a more recent computer. However, the version of ROS1 on the robot is Hydro, which is more than a decade old and predates ROS2 development, i.e. it is not compatible with a ROS1-ROS2 bridge. 

    There are thus a handful of options to consider: One would be to upgrade the ROS1 version of the robot to a version that supports the bridge, such as Melodic or Noetic. However, this would require a significant amount of work and may cause compatibility issues with the outdated software on the robot. Another option would be to use a different computer with a more recent version of ROS1 and use it as a middleware between the robot and the ROS2 navigation stack. This would allow for a more seamless integration of the two systems, but would require additional hardware and software setup and create an unneccesarily complex system. 

    \pagebreak

    \subsection{Writing Custom Programs}

    Using the ROS demo packages as a reference, I was able to write my own custom programs to control the YouBot. This involved using the ROS packages and drivers on the onboard computer to send commands to the motors through the \/cmd\_vel topic. While primitive, this allows for a simmple and intuitive way to control the robot's movement. This could be further extended to include more complex movement through python scripts and other ROS nodes and packages.

    To do this, first create a new package using the catkin command. This will create a new folder in the src directory of your catkin workspace. You can then create a new python script within this folder and use the ROS packages and drivers to send commands to the motors.

    remember to either source the catkin workspace everytime in a new terminal, or add the source command to your .bashrc file.

    After doing this, you can create a new python script within this folder and use the ROS packages and drivers to send commands to the motors. 

    

    \begin{verbatim}
    Text enclosed inside \texttt{verbatim} environment 
    is printed directly 
    and all \LaTeX{} commands are ignored.
    \end{verbatim}


   
    \pagebreak

    \subsection{Experimental Setup for Movement and Odometry}

    \notes{here, ill discuss the experimental setup for testing movement and odometry.  this should include the two experiments of moving linearly and rotating, and discuss how error is calculated. probably discuss negative feedback and PID control as well, random, percentage, consistent error, etc.}

    Taking into account the various inconsistencies noticed whilst running custom programs, some experiments were set up to test the movement and odometry of the YouBot. Since this error seems to be a combination of the robot's own motor control as well as the odometry falling out of calibration, it is important to quantify this error and understand how it may be corrected. 



    \notes{different speeds? proportional or fixed error? does the odometry also drift?}

    20 times per experiment

    Taking into account the various inconsistencies observed while running custom movement programs on the YouBot platform, a series of experiments were conducted to evaluate the accuracy of its movement and odometry. The goal was to quantify the types and sources of errors that arise during both linear and rotational motion, and to assess how these errors can be corrected or compensated for.

    \subsubsection*{Experimental Procedure}

    Two main experiments were designed: one for testing linear forward motion and the other for in-place rotation. In the linear movement test, the robot was commanded to travel forward by a set distance, while in the rotation test, the robot was commanded to rotate by a fixed angle (e.g., 90°). Each command was executed at different speed settings to observe whether error behavior varied with velocity.

    Each experiment was repeated 20 times to ensure statistical significance and to detect any patterns of consistency or randomness in the errors. Measurements of the actual displacement and orientation were obtained using external references (e.g., floor markings or video tracking), and compared against the internal odometry values reported by the robot.

    \subsubsection*{Experiment Configurations}

    \begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
    \textbf{Test ID} & \textbf{Type} & \textbf{Speed (m/s or rad/s)} & \textbf{Target (m or deg)} \\
    \hline
    L1 & Linear & 0.2 m/s & 1.0 m \\
    L2 & Linear & 0.4 m/s & 1.0 m \\
    L3 & Linear & 0.2 m/s & 0.5 m \\
    R1 & Rotation & 0.5 rad/s & 90° \\
    R2 & Rotation & 1.0 rad/s & 90° \\
    \hline
    \end{tabular}
    \caption{Summary of movement and odometry test configurations}
    \end{table}

    Each test case involved issuing a velocity command for a precise duration such that the robot would cover the target distance or angle, assuming ideal conditions. The difference between the expected and actual outcomes was used to calculate both positional and orientation errors.

    \subsubsection*{Types of Errors Observed}

    During the experiments, several types of errors were encountered:

    \begin{itemize}
        \item \textbf{Systematic Errors:} These occurred consistently in the same direction or magnitude, such as under-rotation by a fixed angle or consistent overshoot in distance. Causes included calibration mismatches, wheel radius misestimation, or delay in motor response.
        
        \item \textbf{Random Errors:} Small variations due to factors like sensor noise, surface friction inconsistencies, or transient slippage. These were not consistent across trials and contributed to spread in the results.

        \item \textbf{Proportional Errors:} Errors that scaled with speed or distance, such as increasing overshoot at higher speeds. This suggested control loop latency or imperfect motor linearity.

        \item \textbf{Fixed Offsets:} Some errors were fixed and independent of input command, like a consistent 2 cm drift to one side. These often pointed to physical asymmetries or encoder misalignments.

        \item \textbf{Odometry Drift:} Over longer trials or repeated motion without reset, odometry drift became more apparent, particularly in rotational tracking.
    \end{itemize}

    \subsubsection*{Correction Strategies}

    To address the errors above, multiple correction strategies were explored:

    \begin{itemize}
        \item \textbf{PID Control:} Implementing a PID loop helped reduce overshoot and improve convergence during both linear and rotational motion. Negative feedback from odometry or external position estimates was used to dynamically adjust motor outputs.

        \item \textbf{Calibration:} Careful calibration of wheel radius, wheelbase, and encoder resolution helped reduce systematic errors.

        \item \textbf{Compensation Factors:} Where errors were consistent and repeatable, simple scalar correction factors were applied post hoc to odometry readings.

        \item \textbf{Sensor Fusion:} Although not implemented in this basic test, more advanced setups could integrate IMUs or vision-based SLAM for odometry correction and drift reduction.

        \item \textbf{Averaging Trials:} For random noise, statistical averaging over multiple trials helped establish a more reliable error profile.
    \end{itemize}

    These experiments form the foundation for understanding the motion characteristics of the YouBot and inform future work in navigation, localization, and control refinement.
    \pagebreak



    \subsection{Battery Replacement}



    \notes{draft 1, 11.05 12pm\\
    Here are some good web pages about the Slealed Lead Acid (SLA) batteries:
https://batterymasters.co.uk/blog/post/How%20Do%20Sealed%20Lead%20Acid%20Batteries%20Work
and
https://www.power-sonic.com/blog/how-to-charge-a-lead-acid-battery/
and
https://www.powerstream.com/SLA.htm}

    As previously mentioned, the YouBot came with three 24V SLA batteries. Two of these were the original batteries included with the YouBot, and one was a makeshift battery put together by Vesa in 2019. All three batteries were unusable. This section thus documents the technology behind the SLA batteries, the testing of the original batteries, replacing and testing a new battery, and future battery options. 

    \subsubsection{SLA Battery Overview}

    Sealed lead-acid (SLA) batteries operate based on a reversible chemical reaction between lead plates, lead dioxide and sulfuric acid electrolyte. When the battery discharges, the substances react to form lead sultfate and water, releasing electrical energy. During charging, this reaction is reversed.

    These batteries are quite simple, robust, inexpensive and safe to use, indicating the reason for use in this scenario. However, they require some maintainence, and should undergo full discharge and charge cycles regularly to keep them in a good state. If they are not used regularly, they can suffer from sulphation, where lead sulfate crystals gradually form on the plates of the battery. This process is irreversible and permanently impairs the battery's capabilities. Cheaper SLA batteries are more prone to this issue due to lower quality materials, and one may only expect a maximum lifespan of 3-5 years from them. 

    SLA batteries are furthermore sealed and contain one-way valves to prevent internal pressure buildup due to production of hydrogen and oxygen gas. Normally these gases recombine back into water, but overcharging can force gas release, leading in gradual water loss. 

    The recommended voltage for charging SLA batteries is 2.3 volts per cell (2V), or 13.8V for a 6-cell (12V) battery, or 27.6V for a 12-cell (24V) battery. Charging at a lower voltage (i.e. 2V per cell) will not fill up the battery completely, and increase the risk of sulphation, since the lead sulfate crystals will not be fully converted back into active materials. 

    \subsubsection{Testing original batteries}

    To confirm the degradation of the original batteries, we decided to test them using a multimeter. The two original batteries were completely dead, and did not show any voltage when connected to the multimeter. The makeshift battery showed some voltage, but it was far too low to be usable out the gate. This battery was put together using two 12V SLA batteries, where each battery was individually connected to the 4-pin XLR connector. The YouBot internally connects them in series to create a 24V battery.   
    
    Vesa attempted to revive this battery through desulphation, where a higher-than-recommended voltage (in this case, 30V) is applied to the battery to force current through the hardened sulphate layers and dissolve them. 

    This seemed initially promising: the battery was accepting a charge and its voltage was increasing. However, this was only temporary, as the battery quickly lost voltage again after charging, suggesting that the sulphation was very severe. While some surface conductivity was perhaps restored, the effective area of the electrode plates was still very small, resulting in a very low capacity. As such, the battery was not usable for our purposes.  

    \subsubsection{Replacing batteries}

    \notes{maybe here we can link to the specific batteries used? the dimensions would be neat as well...}

    We decided to remake the makeshift battery using two new 12V SLA batteries of the same dimensions. While the previous batteries were Bitelma batteries, we bought some from Leader this time. These batteries were 12V 5.4Ah batteries. We tested them using a multimeter and used a car charger to charge them overnight. 
    
    The old batteries were removed from their casing and all relevant connections and pieces to structure the battery were removed. The new batteries were then appropriately connected to the 4-pin XLR connector \notes{maybe mention the pinout here?}, and the structural pieces were reattached with tape. After putting the casing back on, we were able to connect the new battery to the YouBot and power it on. The YouBot detects the two batteries and shows their individual voltages, confirming that the battery works. While it's not hermetically sealed, it works well for the purposes of this project. 

    \subsubsection{Future Battery Options}

    While we have replaced the SLA batteries with a makeshift one at a rather inexpensive cost, these batteries will not last long and will be prone to the same issues as the original batteries. 

    An ideal candidate for a replacement battery techonology would be lithium-iron-phosphate (LiFePO4) batteries. These batteries are more expensive, but have multiple advantages over SLA batteries. They have longer lifespans, higher energy density, lighter weight, and are less prone to degradation. However, they would also need an integrated battery management system (BMS) to ensure safe operation, and potentially some custom hardware to fit the dimensions of the YouBot's battery compartment. 


    
    \subsection{Sensors}
    \subsubsection{Kinect Camera and libfreenect}

    The Kinectv1 camera is a depth and RGB camera that was originall designed and sold in tandem with the XBOX 360 to enable motion tracking and gaming. Due to its low cost, high availability and ease of use, it has indirectly become a popular choice for robotics research as well. 

    We can use open-source software such as libfreenect to access the data from the various sensors on the module.


    \notes{discuss the libfreenect library, how to install it, and how it could be used within ROS.}


    \subsubsection{Hokuyo URG-04LX Laser Rangefinder}

    The Hokuyo URG-04LX is a 2D laser rangefinder that is commonly used in robotics research. It is a compact and lightweight sensor that provides high-resolution distance measurements in a 240-degree field of view. The URG-04LX is capable of measuring distances up to 4 meters with an accuracy of +/- 10 mm. It communicates with the onboard computer using a serial interface, making it easy to integrate into existing systems.

    \notes{discuss installing the drivers and whatnot, and how to use it within ROS and rqt.}

    \pagebreak

    \section{Future Applications}

    In this section we will discuss a potential future application of the KUKA YouBot, in the context of the T\&R method of navigation. The T\&R method is a form of visual SLAM, where the robot can be "taught" a path through a static environment using a camera. The robot then uses this information to enable it to repeat the path movement autonomously through key frames it has saved from the environment. This method is simple yet effective in its use cases and can be used in a variety of applications, such as industrial automation, home robotics, service, etc.

    t\&r is not the best implementation of the youbot
    
    platform and real world application

    why im a bit skeptical about 
    trying to implement t\&r in the context of assistive platform 
    trying to present as an application as a playform that can later on be used to execute repetitive task based on the experience of a platform with 

    speculative : presenting it in terms of real-world applications

    flexible intra-logistics
    human awareness and flexibility 
    seamless human-robot existence

    While the YouBot holds the potential capabilities for undertaking Teach and Repeat, its abilities as a mobile industrial robot base would be better suited for real-world applications within closed environments as an assistive platform. 

    This robot base would be most useful in an assisstie  sense, where it assists humans in completing rather basic and repetitive tasks, like fetching beer. 

    The KUKA YouBot, with its omnidirectional mobile base, offers a flexible platform for experimentation and prototyping in robotics. While the Teach and Repeat (T\&R) method---where a robot is ``taught'' a path using visual cues and then autonomously repeats it---has proven effective in certain domains, its real-world utility as a navigation strategy for assistive platforms is nuanced and context-dependent.

    \subsection{Potential Use Cases for the YouBot Mobile Base}

    The YouBot's mobile base, independent of its manipulator arm, is particularly well-suited for:

    \begin{itemize}
        \item \textbf{Flexible Intra-Logistics:} The YouBot can transport materials, components, or finished goods within factories or laboratories, adapting to dynamic layouts and avoiding obstacles thanks to its omnidirectional drive system. This makes it valuable for automating repetitive transport tasks in manufacturing, electronics, and pharmaceutical environments~.
        \item \textbf{Assistive Service Robotics:} In assistive roles, the mobile base could help with tasks such as fetching objects (e.g., drinks, tools), delivering supplies, or guiding people in structured indoor environments. Such applications are particularly relevant in healthcare, offices, or smart homes, where repetitive, low-complexity tasks can be offloaded from humans to robots~.
        \item \textbf{Research and Prototyping Platform:} The YouBot is widely used in academic and industrial research for developing and testing navigation, mapping, and multi-robot coordination algorithms. Its open interfaces and modular design make it ideal for experimentation in logistics, navigation, and human-robot interaction~.
        \item \textbf{Quality Control and Inspection:} The platform can be equipped with sensors or cameras to autonomously inspect products, monitor environments, or perform routine checks in hazardous or hard-to-reach areas~.
    \end{itemize}

    \subsection{Teach and Repeat (T\&R) in Context}

    The T\&R method, while simple and robust for repeated path following in static environments, has limitations when applied to assistive platforms:

    \begin{itemize}
        \item \textbf{Limited Flexibility:} T\&R excels in environments where the path and surroundings are relatively unchanging. In dynamic or human-populated spaces, its lack of real-time adaptability can be a drawback compared to more advanced SLAM or AI-based navigation systems.
        \item \textbf{Suitability for Repetitive Tasks:} For repetitive, well-defined routes---such as material delivery within a warehouse, or routine inspection rounds---T\&R can be a practical, low-compute solution. However, its application as a general-purpose assistive platform is more speculative, especially where human interaction and environmental variability are significant.
        \item \textbf{Platform Capabilities:} The YouBot's mobile base is robust and maneuverable, making it a strong candidate for T\&R-based applications in controlled settings. Its open architecture allows easy integration of additional sensors or navigation modules, enabling researchers to extend beyond T\&R as needed.
    \end{itemize}

    \subsection{Speculative and Emerging Applications}

    Looking forward, the YouBot mobile base could play a role in:

    \begin{itemize}
        \item \textbf{Seamless Human-Robot Coexistence:} As part of smart environments, YouBots could support flexible logistics, on-demand delivery, and collaborative tasks alongside humans, leveraging both T\&R for routine paths and more advanced navigation for dynamic tasks.
        \item \textbf{Education and Training:} Its accessibility and open-source support make it an excellent tool for teaching robotics concepts, prototyping new algorithms, or participating in competitions such as RoboCup@Work.
        \item \textbf{Translational Research:} Innovations and algorithms developed on the YouBot can be scaled up to larger, industrial-grade mobile platforms, facilitating technology transfer from the lab to real-world production lines.
    \end{itemize}

    \subsection{Summary Table: Potential Use Cases for the KUKA YouBot Mobile Base}

    \begin{table}[h!]
    \centering
    \begin{tabular}{|l|p{7cm}|l|}
    \hline
    \textbf{Application Area} & \textbf{Description} & \textbf{Reference} \\
    \hline
    Intra-logistics & Material transport, flexible routing in factories, labs, or warehouses &  \\
    Assistive service robotics & Fetching/delivery tasks, guidance, support in healthcare or home environments &  \\
    Research and prototyping & Testing navigation, SLAM, multi-robot systems, and human-robot interaction & \\
    Inspection and quality control & Autonomous inspection, monitoring, and data collection in industrial or hazardous settings &  \\
    Education and training & Robotics teaching, student projects, and competitions &  \\
    \hline
    \end{tabular}
    \caption{Potential Use Cases for the KUKA YouBot Mobile Base}
    \end{table}

    \subsection{Conclusion}

    While the KUKA YouBot’s mobile base is not the optimal platform for all assistive applications---especially those requiring high flexibility and human awareness---it remains a valuable tool for developing and demonstrating repetitive, structured tasks. Its use in T\&R navigation is best suited for closed, static environments, but its modularity and open architecture allow for broader experimentation and real-world prototyping in logistics, research, and assistive robotics.

    


    \pagebreak

    \section{Reflection}

    \notes{draft 1, 11.05 6pm}

    In this section, I will reflect on the outcomes of this project. This will include an overview of project management practices and planning, alongside my learnings and personal feelings about the project. 

    \subsection{Project Evolution}

    As disccused previously, the initial goal of this project was much more concrete and ambitious, with an ultimate aim of enabling Teach and Repeat on a decade-old robot whilst using something like ROS2 Jazzy. This was simply not feasible with the outdated software and hardware, lack of documentation, my own lack of experience, and the overall time and resource constraints for completing this project. Furthermore, this project was a significant different experience from any other course I have taken in the past.
    
    My initial approach to project management was very linear and straighforward, with the understanding that there would be no hiccups or issues along the way. I had the following time-table in mind: \notes{maybe insert a table showcasing the plan here?} While this was initially rewarding as I made progress in individual tasks (i.e. Kinect camera, booting up computer, static IP, etc.), momentum was quickly lost when it came to integrating these tasks into a cohesive system, through the use of the ROS1-ROS2 bridge. 

    \subsection{AGILE}

    The new mindset I undertook was inspired by the AGILE project management methodology, which takes a much more flexible and iterative approach to project management. While the long-term goals are still important, the focus is on short-term goals and iterations. This allows for a more flexible approach, where the ending goal can be adjusted based on constraints, feedback, and progress. 

    While this also indirectly means that the project may not be concretely completed, it led to a more flexible exploration of the robot's capabilities and limitations. It furthermore relieved me of the pressure of having to complete a specific (and steep) goal, and gave me breathing space to play around with the available components more freely. This was much more rewarding and enjoyable.

    Undertaking this mindset required time and patience, where I had to learn to accept that not everything would go according to plan. It furthermore required me to be more open to feedback, and actively focusing on short-term goals. 

    \subsection{Final Thoughts}

    Overall, despite the various challenges faced, I am very happy with my progress and learning outcomes regarding this project. I was able to successfully revive the KUKA YouBot to a usable state, gain a deeper understanding of the ROS ecosystem, Linux, bash scripting, alongside the various hardware components of the robot. More importantly, I learned to manage projects with the understanding of personal and technical constraints. I'd like to thank my advisor for his provision of a different perspective on the project, explanations of everything and constant patience.  


    \newpage

    \nocite{*}
    \printbibliography

    \newpage

    \appendix


    \section{User Manual for the KUKA YouBot}

    \subsection{
     How to turn on the YouBot
    }

    \subsection{.bashrc recap}

    \subsection{How to run original demos}

    
    
\end{document}
