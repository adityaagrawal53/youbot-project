@bachelorsthesis{Tsogias2016,
  author       = {Ioannis Tsogias},
  title        = {{Kinematic Analysis of a KUKA YouBot}},
  school       = {National Technical University of Athens},
  year         = {2016},
  url          = {https://dspace.lib.ntua.gr/xmlui/handle/123456789/43358},
  doi          = {10.26240/heal.ntua.12581},
}

@misc{archiveYouBotStore,
	author = {},
	title = {you{B}ot {S}tore --- web.archive.org},
	url = {https://web.archive.org/web/20170318163736/http://www.youbot-store.com/developers/},
	year = {},
	note = {[Accessed 23-04-2025]},
}

@misc{janpaulusYouBotDriver,
	author = {},
	title = {you{B}ot {D}river --- janpaulus.github.io},
	howpublished = {\url{https://janpaulus.github.io/}},
	year = {},
	note = {[Accessed 23-04-2025]},
}

@misc{githubYoubotOverview,
	author = {},
	title = {youbot - {O}verview --- github.com},
	howpublished = {\url{https://github.com/youbot}},
	year = {},
	note = {[Accessed 23-04-2025]},
}

@article{KARASTOYANOV201844,
title = {Reuse of Industrial Robots},
journal = {IFAC-PapersOnLine},
volume = {51},
number = {30},
pages = {44-47},
year = {2018},
note = {18th IFAC Conference on Technology, Culture and International Stability TECIS 2018},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2018.11.243},
url = {https://www.sciencedirect.com/science/article/pii/S240589631832915X},
author = {D. Karastoyanov and S. Karastanev},
keywords = {Industrial robots, Reuse, EoL, Die-casting},
abstract = {EoL of industrial robots is currently only a partially solved problem. Usually the average life time of an industrial robot in industry, depending from the working and maintaining conditions, is in average 6-7 years because of the advances in IT hard-and software. Especially with the new headlines Procedure 4.0, Cyberphysical Systems (CPS). Most of the older robot-controllers cannot be used for these methods of production automation. The average lifetime of the robot mechanics is, depending from the industrial use between 10 and 20 years. A special case are robots for educational and research purposes. They should be also replaced every 5 - 7 years. Until now there was only the possibility to disassemble and sell the mechanical parts as spare parts. Therefore in this paper a new approach for reuse will be presented. The main idea beyond consists in using the mechanics of selected "old" industrial robots and a completely reengineering of the controller hard and software according to the latest requests from manufacturing automation. The authors created this idea some years ago and have developed a procedure geared to the automation of auxiliary processes in the die-casting industry. This procedure was applied to two types of robots. They are now equipped with new controllers from a local company which allows to include these robots in "modern" manufacturing automation systems. The new software and interface are more user-friendly and easy to use by the users in this field of automation.}
}

@article{SOORI202354,
title = {Artificial intelligence, machine learning and deep learning in advanced robotics, a review},
journal = {Cognitive Robotics},
volume = {3},
pages = {54-70},
year = {2023},
issn = {2667-2413},
doi = {https://doi.org/10.1016/j.cogr.2023.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S2667241323000113},
author = {Mohsen Soori and Behrooz Arezoo and Roza Dastres},
keywords = {Artificial intelligence, Machine learning, Deep learning, Advanced robotics},
abstract = {Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL) have revolutionized the field of advanced robotics in recent years. AI, ML, and DL are transforming the field of advanced robotics, making robots more intelligent, efficient, and adaptable to complex tasks and environments. Some of the applications of AI, ML, and DL in advanced robotics include autonomous navigation, object recognition and manipulation, natural language processing, and predictive maintenance. These technologies are also being used in the development of collaborative robots (cobots) that can work alongside humans and adapt to changing environments and tasks. The AI, ML, and DL can be used in advanced transportation systems in order to provide safety, efficiency, and convenience to the passengers and transportation companies . Also, the AI, ML, and DL are playing a critical role in the advancement of manufacturing assembly robots, enabling them to work more efficiently, safely, and intelligently. Furthermore, they have a wide range of applications in aviation management, helping airlines to improve efficiency, reduce costs, and improve customer satisfaction. Moreover, the AI, ML, and DL can help taxi companies in order to provide better, more efficient, and safer services to customers. The research presents an overview of current developments in AI, ML, and DL in advanced robotics systems and discusses various applications of the systems in robot modification. Further research works regarding the applications of AI, ML, and DL in advanced robotics systems are also suggested in order to fill the gaps between the existing studies and published papers. By reviewing the applications of AI, ML, and DL in advanced robotics systems, it is possible to investigate and modify the performances of advanced robots in various applications in order to enhance productivity in advanced robotic industries.}
}

@misc{KUKAYouBotFlyer,
  author       = {KUKA},
  title        = {YouBot Product Flyer},
  year         = {2017},
  howpublished = {\url{https://web.archive.org/web/20170829075021/http://www.youbot-store.com/media/wysiwyg/pdf/youbot_product_flyer.pdf}},
  note         = {Accessed: 2025-06-05}
}

@manual{KUKAYouBotManual2013,
  title        = {KUKA youBot User Manual},
  author       = {{Locomotec}},
  year         = {2013},
  edition      = {version 1.02},
  month        = feb,
  note         = {Unpublished manual, available as PDF.}
}

@misc{ubahnverleih2016,
  author       = {ubahnverleih},
  title        = {RoboCup 2016 Leipzig - KUKA youBot},
  year         = {2016},
  month        = jul,
  day          = {3},
  howpublished = {\url{https://commons.wikimedia.org/wiki/File:RoboCup_2016_Leipzig_-_KUKA_youBot_(2).jpg}},
  note         = {Own work. Image retrieved from Wikimedia Commons.}
}

@misc{YouBotSpecs2016,
  title        = {YouBot Detailed Specifications},
  year         = {2016},
  howpublished = {\url{https://web.archive.org/web/20160121124150/http://www.youbot-store.com/wiki/index.php/YouBot_Detailed_Specifications}},
  note         = {Accessed: 2025-06-05}
}

@misc{HokuyoURG04LXUG01,
  author       = {Hokuyo Automatic Co., Ltd.},
  title        = {URG-04LX-UG01 Scanning Rangefinder},
  year         = {2016},
  howpublished = {\url{https://www.hokuyo-aut.jp/search/single.php?serial=166}},
  note         = {Accessed: 2025-06-05}
}

@misc{OpenKinectLibfreenect,
  author       = {OpenKinect},
  title        = {libfreenect:  Drivers and libraries for the Xbox Kinect device on Windows, Linux, and OS X},
  year         = {2024},
  howpublished = {\url{https://github.com/OpenKinect/libfreenect}},
  note         = {Accessed: 2025-06-05}
}

@misc{YouBotSensorPlate2016,
  title        = {Mounting and Sensor Plate, KUKA youBot Store},
  year         = {2016},
  howpublished = {\url{https://web.archive.org/web/20160613151621/http://www.youbot-store.com/accessories/mounting-and-sensor-plate}},
  note         = {Accessed: 2025-06-05}
}

@misc{WaybackMachine,
  title        = {Wayback Machine},
  howpublished = {\url{https://web.archive.org/}},
  note         = {Accessed: 2025-06-05}
}

@online{Shahrivar2018,
  author       = {Ebrahim Shahrivar},
  title        = {Visual Teach and Repeat: A Closer Look (PART 1)},
  year         = {2018},
  month        = jul,
  day          = {31},
  url          = {https://clearpathrobotics.com/blog/2018/07/visual-teach-and-repeat-closer-look-part-1/},
  note         = {Accessed: 2025-06-05}
}

@INPROCEEDINGS{10611662,
  author={Nourizadeh, Payam and Milford, Michael and Fischer, Tobias},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Teach and Repeat Navigation: A Robust Control Approach}, 
  year={2024},
  volume={},
  number={},
  pages={2909-2916},
  keywords={Uncertainty;Navigation;Wheels;Robot sensing systems;Robustness;Odometry;Mobile robots},
  doi={10.1109/ICRA57147.2024.10611662}}

@article{NITSCHE2020103577,
title = {Visual-inertial teach and repeat},
journal = {Robotics and Autonomous Systems},
volume = {131},
pages = {103577},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103577},
url = {https://www.sciencedirect.com/science/article/pii/S0921889020304176},
author = {Mat√≠as Nitsche and Facundo Pessacg and Javier Civera},
keywords = {UAV, Embedded, Navigation, Visual-inertial, Stereo, Teach-and-replay, Relative},
abstract = {Teach and Repeat (T&R) refers to the technology that allows a robot to autonomously follow a previously traversed route, in a natural scene and using only its onboard sensors. In this paper we present a Visual-Inertial Teach and Repeat (VI-T&R) algorithm that uses stereo and inertial data and targets Unmanned Aerial Vehicles with limited on-board computational resources. We propose a tightly-coupled relative formulation of the visual-inertial constraints that is tailored to the T&R application. In order to achieve real-time operation on limited hardware, we reduce the problem to motion-only visual-inertial Bundle Adjustment. In the repeat stage, we detail how to generate a trajectory and smoothly follow it with a constantly changing relative frame. The proposed method is validated in simulated environments, using real sensor data from the public EuRoC dataset, and using our own robotic setup and closed-loop control. Our experimental results demonstrate high accuracy and real-time performance both on a standard desktop system and on a low-cost Odroid X-U4 embedded computer.}
}